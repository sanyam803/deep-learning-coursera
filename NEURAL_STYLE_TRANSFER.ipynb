{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\NEURAL TRANSFER\n"
     ]
    }
   ],
   "source": [
    "cd E:\\NEURAL TRANSFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_vgg_model(\"imagenet-vgg-verydeep-19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': <tf.Variable 'Variable:0' shape=(1, 300, 400, 3) dtype=float32_ref>, 'conv1_1': <tf.Tensor 'Relu:0' shape=(1, 300, 400, 64) dtype=float32>, 'conv1_2': <tf.Tensor 'Relu_1:0' shape=(1, 300, 400, 64) dtype=float32>, 'avgpool1': <tf.Tensor 'AvgPool:0' shape=(1, 150, 200, 64) dtype=float32>, 'conv2_1': <tf.Tensor 'Relu_2:0' shape=(1, 150, 200, 128) dtype=float32>, 'conv2_2': <tf.Tensor 'Relu_3:0' shape=(1, 150, 200, 128) dtype=float32>, 'avgpool2': <tf.Tensor 'AvgPool_1:0' shape=(1, 75, 100, 128) dtype=float32>, 'conv3_1': <tf.Tensor 'Relu_4:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv3_2': <tf.Tensor 'Relu_5:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv3_3': <tf.Tensor 'Relu_6:0' shape=(1, 75, 100, 256) dtype=float32>, 'conv3_4': <tf.Tensor 'Relu_7:0' shape=(1, 75, 100, 256) dtype=float32>, 'avgpool3': <tf.Tensor 'AvgPool_2:0' shape=(1, 38, 50, 256) dtype=float32>, 'conv4_1': <tf.Tensor 'Relu_8:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv4_2': <tf.Tensor 'Relu_9:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv4_3': <tf.Tensor 'Relu_10:0' shape=(1, 38, 50, 512) dtype=float32>, 'conv4_4': <tf.Tensor 'Relu_11:0' shape=(1, 38, 50, 512) dtype=float32>, 'avgpool4': <tf.Tensor 'AvgPool_3:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_1': <tf.Tensor 'Relu_12:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_2': <tf.Tensor 'Relu_13:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_3': <tf.Tensor 'Relu_14:0' shape=(1, 19, 25, 512) dtype=float32>, 'conv5_4': <tf.Tensor 'Relu_15:0' shape=(1, 19, 25, 512) dtype=float32>, 'avgpool5': <tf.Tensor 'AvgPool_4:0' shape=(1, 10, 13, 512) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_content_cost\n",
    "\n",
    "def compute_content_cost(a_C, a_G):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_content -- scalar that you compute using equation 1 above.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list();\n",
    "    \n",
    "    # Reshape a_C and a_G (≈2 lines)\n",
    "    a_C_unrolled = tf.reshape(a_C,shape=(m,n_H*n_W,n_C));\n",
    "    a_G_unrolled =  tf.reshape(a_G,shape=(m,n_H*n_W,n_C));\n",
    "    \n",
    "    # compute the cost with tensorflow (≈1 line)\n",
    "    J_content = (1/(4*n_H*n_W*n_C))*(tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled,a_G_unrolled))));\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: gram_matrix\n",
    "\n",
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (n_C, n_H*n_W)\n",
    "    \n",
    "    Returns:\n",
    "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈1 line)\n",
    "    GA = tf.matmul(A,tf.transpose(A));\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_layer_style_cost\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
    "    a_S = tf.reshape(tf.transpose(a_S),shape=(n_C,n_H*n_W)); # carefull only changing shape will \n",
    "                                                              #not work u need to take transpose as well\n",
    "    a_G = tf.reshape(tf.transpose(a_G),shape=(n_C,n_H*n_W));\n",
    "\n",
    "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
    "    GS =  gram_matrix(a_S)\n",
    "    GG =  gram_matrix(a_G)\n",
    "\n",
    "    # Computing the loss (≈1 line)\n",
    "    J_style_layer = (1/(4*n_C*n_C*(n_H*n_W)*(n_H*n_W)))*tf.reduce_sum(tf.square(tf.subtract(GS,GG)));\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    model -- our tensorflow model\n",
    "    STYLE_LAYERS -- A python list containing:\n",
    "                        - the names of the layers we would like to extract style from\n",
    "                        - a coefficient for each of them\n",
    "    \n",
    "    Returns: \n",
    "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    J_style = 0\n",
    "\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = model[layer_name]\n",
    "\n",
    "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
    "        a_S = sess.run(out)\n",
    "\n",
    "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n",
    "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
    "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
    "        a_G = out\n",
    "        \n",
    "        # Compute style_cost for the current layer\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "\n",
    "        # Add coeff * J_style_layer of this layer to overall style cost\n",
    "        J_style += coeff * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: total_cost\n",
    "\n",
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost function\n",
    "    \n",
    "    Arguments:\n",
    "    J_content -- content cost coded above\n",
    "    J_style -- style cost coded above\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost as defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈1 line)\n",
    "    J = (alpha*J_content)+(beta*(J_style));\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Content Image\n",
    "content_image = scipy.misc.imread(\"Content/saksham.jpg\")\n",
    "content_image= reshape_and_normalize(content_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Style Image\n",
    "style_image = scipy.misc.imread(\"Styles/style2.jpg\")\n",
    "style_image = reshape_and_normalize(style_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the content image to be the input of the VGG model.  \n",
    "sess.run(model['input'].assign(content_image))\n",
    "\n",
    "# Select the output tensor of layer conv4_2\n",
    "out = model['conv4_2']\n",
    "\n",
    "# Set a_C to be the hidden layer activation from the layer we have selected\n",
    "a_C = sess.run(out)\n",
    "\n",
    "# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n",
    "# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
    "# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
    "a_G = out\n",
    "\n",
    "# Compute the content cost\n",
    "J_content = compute_content_cost(a_C, a_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign the input of the model to be the \"style\" image \n",
    "sess.run(model['input'].assign(style_image))\n",
    "\n",
    "# Compute the style cost\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line)\n",
    "J = total_cost(J_content, J_style, alpha = 10, beta = 40)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimizer (1 line)\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "# define train_step (1 line)\n",
    "train_step = optimizer.minimize(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 200):\n",
    "    \n",
    "    # Initialize global variables (you need to run the session on the initializer)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    init = tf.global_variables_initializer();\n",
    "    sess.run(init)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "    \n",
    "        # Run the session on the train_step to minimize the total cost\n",
    "        ### START CODE HERE ### (1 line)\n",
    "        \n",
    "        sess.run([train_step])\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute the generated image by running the session on the current model['input']\n",
    "        ### START CODE HERE ### (1 line)\n",
    "        generated_image = sess.run(model['input'])\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i%20 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "            \n",
    "            # save current generated image in the \"/output\" directory\n",
    "            save_image(\"output/\" + str(i)+\"a\" + \".png\", generated_image)\n",
    "    \n",
    "    # save last generated image\n",
    "    save_image('output/generated_image1.jpg', generated_image)\n",
    "    \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "total cost = 7.10114e+09\n",
      "content cost = 11724.0\n",
      "style cost = 1.77526e+08\n",
      "Iteration 20 :\n",
      "total cost = 7.32515e+08\n",
      "content cost = 22265.8\n",
      "style cost = 1.83073e+07\n",
      "Iteration 40 :\n",
      "total cost = 3.23717e+08\n",
      "content cost = 23600.6\n",
      "style cost = 8.08703e+06\n",
      "Iteration 60 :\n",
      "total cost = 2.06549e+08\n",
      "content cost = 24145.3\n",
      "style cost = 5.15769e+06\n",
      "Iteration 80 :\n",
      "total cost = 1.55491e+08\n",
      "content cost = 24384.1\n",
      "style cost = 3.88118e+06\n",
      "Iteration 100 :\n",
      "total cost = 1.25289e+08\n",
      "content cost = 24568.2\n",
      "style cost = 3.12609e+06\n",
      "Iteration 120 :\n",
      "total cost = 1.04483e+08\n",
      "content cost = 24719.6\n",
      "style cost = 2.6059e+06\n",
      "Iteration 140 :\n",
      "total cost = 8.92453e+07\n",
      "content cost = 24854.6\n",
      "style cost = 2.22492e+06\n",
      "Iteration 160 :\n",
      "total cost = 7.77502e+07\n",
      "content cost = 24979.6\n",
      "style cost = 1.93751e+06\n",
      "Iteration 180 :\n",
      "total cost = 6.88213e+07\n",
      "content cost = 25092.6\n",
      "style cost = 1.71426e+06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ -2.51395264e+01,  -6.18858147e+01,  -5.67080040e+01],\n",
       "         [ -3.20002594e+01,  -4.84300232e+01,  -5.62694969e+01],\n",
       "         [ -4.91070633e+01,  -5.57087593e+01,  -5.51056175e+01],\n",
       "         ..., \n",
       "         [  1.56590195e+01,  -1.35663176e+01,  -1.67613089e+00],\n",
       "         [  2.38681755e+01,  -6.49265814e+00,   1.19947720e+01],\n",
       "         [  1.23373966e+01,  -1.07286816e+01,  -1.21425658e-01]],\n",
       "\n",
       "        [[ -4.60208778e+01,  -4.95382805e+01,  -7.00648117e+01],\n",
       "         [ -3.31508522e+01,  -5.92648087e+01,  -4.31735153e+01],\n",
       "         [ -6.38830109e+01,  -5.44044800e+01,  -7.34431000e+01],\n",
       "         ..., \n",
       "         [  7.40297394e+01,   5.24567070e+01,   5.61869507e+01],\n",
       "         [  2.82871380e+01,   2.05070896e+01,   1.17675037e+01],\n",
       "         [  3.26599655e+01,   2.27640581e+00,   2.51063423e+01]],\n",
       "\n",
       "        [[ -2.93164577e+01,  -3.81133957e+01,  -4.30152550e+01],\n",
       "         [ -3.40161538e+00,  -1.88004990e+01,  -1.33399153e+01],\n",
       "         [  3.68730278e+01,   2.01168709e+01,   7.69499493e+00],\n",
       "         ..., \n",
       "         [  8.46872101e+01,   6.78626175e+01,   7.19824219e+01],\n",
       "         [  5.49874763e+01,   5.42225685e+01,   6.06012421e+01],\n",
       "         [  3.26302414e+01,   3.59682426e+01,   1.61005039e+01]],\n",
       "\n",
       "        ..., \n",
       "        [[ -5.63278275e+01,  -7.34621582e+01,  -5.87042618e+00],\n",
       "         [ -7.71501007e+01,  -8.96239243e+01,  -7.84701004e+01],\n",
       "         [  1.46060109e+00,  -1.75131149e+01,  -1.67339725e+01],\n",
       "         ..., \n",
       "         [ -2.03412571e+01,  -3.45602989e+01,  -1.10373182e+01],\n",
       "         [ -2.21158333e+01,  -1.18142109e+01,   2.06240940e+01],\n",
       "         [  4.36984901e+01,   2.25673695e+01,   5.24956093e+01]],\n",
       "\n",
       "        [[ -5.75268364e+01,  -7.82350540e+01,  -1.71829700e+01],\n",
       "         [ -7.00798721e+01,  -7.15920563e+01,  -1.20829254e+02],\n",
       "         [ -2.76666908e+01,  -7.59462051e+01,  -2.83695450e+01],\n",
       "         ..., \n",
       "         [ -5.49402618e+01,  -1.05628052e+01,   1.13862247e+01],\n",
       "         [ -8.82238960e+00,   2.61660242e+00,  -9.15093231e+00],\n",
       "         [  8.91485825e+01,   2.61942844e+01,   1.53798325e+02]],\n",
       "\n",
       "        [[ -1.97892151e+01,  -4.77490234e+01,   1.09013138e+01],\n",
       "         [ -4.55628319e+01,  -6.44771881e+01,  -3.75361786e+01],\n",
       "         [ -4.18822174e+01,  -7.65490494e+01,  -1.46164398e+01],\n",
       "         ..., \n",
       "         [  1.37813072e+01,   8.94127083e+00,   5.03581772e+01],\n",
       "         [  2.73207378e+01,   2.07947006e+01,   4.05819168e+01],\n",
       "         [  1.23206581e+02,   2.04949608e+01,   1.69966827e+02]]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn(sess, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
